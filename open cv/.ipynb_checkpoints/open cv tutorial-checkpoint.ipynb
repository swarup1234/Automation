{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open CV Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading an Image example, and then viewing for 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"images/Balcony 1.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"output\",img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vedio Viewing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-vi271kac\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-38d1c541d783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vedio\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-vi271kac\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"Resources/test_vedio.mp4\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Vedio\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webcam Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# width \n",
    "cap.set(3,640)\n",
    "\n",
    "# height \n",
    "cap.set(4,480)\n",
    "\n",
    "# brightness\n",
    "cap.set(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Vedio\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"images/Balcony 1.jpeg\")\n",
    "kernal = np.ones((5,5),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greay scale coulur\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# bluring the output\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "\n",
    "# edge detecter \n",
    "imgCanny = cv2.Canny(img,100,100)\n",
    "\n",
    "# image dilation [Size and value]\n",
    "imgDialation = cv2.dilate(imgCanny,kernal,iterations=5)\n",
    "\n",
    "# image errosion opposite of dilateion\n",
    "imgEroded = cv2.erode(imgDialation,kernal,iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.imshow(\"Blur Image\", imgBlur)\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.imshow(\"Image Dialation\", imgDialation)\n",
    "cv2.imshow(\"Image Erorded\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 \n",
    "\n",
    "## Resizing and Cropping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/Balcony 2.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resizing the image: width first and height next in resizing\n",
    "imgResize = cv2.resize(img,(800,600))\n",
    "cv2.imshow(\"Resize shape\", imgResize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imgResize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cropping the image: Height first and width next in cropping\n",
    "imgCropped = imgResize[0:400,100:700]\n",
    "cv2.imshow(\"Resize shape\", imgResize)\n",
    "cv2.imshow(\"Cropped shape\", imgCropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 \n",
    "\n",
    "## Shapes and text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((512,600,3),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the colour to blue box in the function \n",
    "img[100:200,0:100]=255,0,0\n",
    "\n",
    "# drawing a line in green colur\n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)\n",
    "\n",
    "# drawing a reectangle in red colur\n",
    "cv2.rectangle(img,(0,0),(250,200),(0,0,255),2)\n",
    "\n",
    "# drawing a circle in red colur\n",
    "cv2.circle(img,(400,50),30,(0,0,255),2)\n",
    "\n",
    "# writing the text in yellow colur\n",
    "cv2.putText(img,\"OPEN CV\",(250,150),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "\n",
    "## Wrap Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"images/Balcony 2.jpeg\")\n",
    "imgResize = cv2.resize(img,(800,600))\n",
    "cv2.imshow(\"Image\", imgResize)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResize = cv2.resize(img,(800,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResize = cv2.putText(imgResize,\"(460,80)\",(460,80),cv2.FONT_HERSHEY_COMPLEX,0.6,(0,255,255),1)\n",
    "imgResize = cv2.putText(imgResize,\"(380,280)\",(380,280),cv2.FONT_HERSHEY_COMPLEX,0.6,(0,255,255),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image\", cv2.rectangle(imgResize,(460,80),(380,280),(0,0,255),2))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "width,height = 300,300\n",
    "pts1 = np.float32([[380,80],[460,80],[380,280],[460,280]])\n",
    "pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "mat = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "imgOutput = cv2.warpPerspective(imgResize,mat,(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image warped \", imgOutput)\n",
    "cv2.imshow(\"Image original\", imgResize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "\n",
    "\n",
    "## Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettin 2 images and stacking them\n",
    "img = cv2.imread(\"images/Balcony 2.jpeg\")\n",
    "img2 = cv2.imread(\"images/Balcony 1.jpeg\")\n",
    "imgResize = cv2.resize(img,(400,300))\n",
    "imgResize2 = cv2.resize(img2,(400,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal stacking \n",
    "hor = np.hstack((imgResize,imgResize2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the output \n",
    "cv2.imshow(\"Horizontal Stack\", hor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettin 2 images and stacking them\n",
    "img3 = cv2.imread(\"images/Bathroom 2.jpeg\")\n",
    "img4 = cv2.imread(\"images/Bathroom 1.jpeg\")\n",
    "imgResize3 = cv2.resize(img3,(400,350))\n",
    "imgResize4 = cv2.resize(img4,(400,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal stacking \n",
    "hor2 = np.hstack((imgResize3,imgResize4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the output \n",
    "cv2.imshow(\"Horizontal Stack\", hor2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertical stacking \n",
    "ver = np.vstack((hor,hor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the output \n",
    "cv2.imshow(\"Vertical Stack\", ver)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack images example function \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "#img = cv2.imread('Resources/lena.png')\n",
    "#imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgStack = stackImages(0.5,([img,img2],[img3,img4]))\n",
    "# showing the output \n",
    "cv2.imshow(\"Final Stack\", imgStack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgStack2 = stackImages(1,([imgResize,imgResize2],[imgResize3,imgResize4]))\n",
    "# showing the output \n",
    "cv2.imshow(\"Final Stack\", imgStack2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 \n",
    "\n",
    "\n",
    "## Colour Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading an image\n",
    "img = cv2.imread(\"images/Kitchen Picture 2.jpeg\")\n",
    "#imgResize = cv2.resize(img,(600,600))\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to hsv image\n",
    "imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatign a dummy function\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "# creating a track bar\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",640,240)\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",179,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"TrackBars\",0,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"TrackBars\",255,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"TrackBars\",0,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"TrackBars\",89,255,empty)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "framewidth = 640\n",
    "frameheight = 480\n",
    "\n",
    "# width \n",
    "cap.set(3,framewidth)\n",
    "\n",
    "# height \n",
    "cap.set(4,frameheight)\n",
    "\n",
    "# brightness\n",
    "cap.set(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = True\n",
    "while out:\n",
    "    # reading an image\n",
    "    #img = cv2.imread(\"images/Kitchen Picture 2.jpeg\")\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # converting to hsv image\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # getting trackbar positions \n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\",\"TrackBars\")\n",
    "    \n",
    "    \n",
    "    # creating a mask\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    "    imgResult2 = cv2.bitwise_and(img,img,mask=cv2.bitwise_not(mask))\n",
    "    \n",
    "    # displaying HSV figure\n",
    "    # cv2.imshow(\"Image\", imgHSV)\n",
    "    # cv2.imshow(\"Mask\", mask)\n",
    "    # cv2.imshow(\"Result\", imgResult)\n",
    "    \n",
    "    imgStack = stackImages(0.5,([img,imgHSV,cv2.bitwise_not(mask)],[mask,imgResult,imgResult2]))\n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        out = False\n",
    "        cv2.waitKey(0)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8\n",
    "\n",
    "\n",
    "## Countours or shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading an image\n",
    "img = cv2.imread(\"images/sshapes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing and copying the image \n",
    "img = cv2.resize(img,(600,400))\n",
    "imgContour = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton to detect, draw and return contours \n",
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(\"Area=\"+str(round(area)))\n",
    "        if area>=50:\n",
    "            cv2.drawContours(imgContour,cnt,-1,(255,0,0),3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            #rint(\"Approx Sides= \"+str(approx)+\"\\n\")\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            if objCor ==3:\n",
    "                objtype = \"Triangle\"\n",
    "            elif objCor == 4 and w==h:\n",
    "                objtype = \"Square\"\n",
    "            elif objCor == 4 and w!=h:\n",
    "                objtype = \"Rectange\"\n",
    "            elif objCor == 5:\n",
    "                objtype = \"Pentagon\"\n",
    "            elif objCor == 6:\n",
    "                objtype = \"Hexagon\"\n",
    "            else:\n",
    "                objtype = \"None\"\n",
    "            \n",
    "            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(imgContour,objtype,\n",
    "                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.5,\n",
    "                        (0,255,255),2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=42\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=3\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=11\n",
      "Area=3\n",
      "Area=3\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=1\n",
      "Area=0\n",
      "Area=9\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=4\n",
      "Area=3\n",
      "Area=17\n",
      "Area=18\n",
      "Area=0\n",
      "Area=1\n",
      "Area=2\n",
      "Area=2\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=4\n",
      "Area=0\n",
      "Area=12\n",
      "Area=0\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=3\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=6\n",
      "Area=6\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=4\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=34\n",
      "Area=0\n",
      "Area=0\n",
      "Area=4\n",
      "Area=2\n",
      "Area=2\n",
      "Area=2\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=5\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=13\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=4\n",
      "Area=0\n",
      "Area=4\n",
      "Area=4\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=4\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=44\n",
      "Area=2\n",
      "Area=6\n",
      "Area=0\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=9\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=18\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=6\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=10\n",
      "Area=10\n",
      "Area=0\n",
      "Area=46\n",
      "Area=0\n",
      "Area=2\n",
      "Area=6\n",
      "Area=2\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=1\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=2\n",
      "Area=3\n",
      "Area=0\n",
      "Area=2\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=0\n",
      "Area=198\n",
      "Area=22\n"
     ]
    }
   ],
   "source": [
    "# getting the image\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "imgCanny = cv2.Canny(img,100,100)\n",
    "getContours(imgCanny)\n",
    "imgResult = cv2.bitwise_and(img,img,mask=imgCanny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgStack = stackImages(1,([img,imgGray,imgBlur],[imgCanny,imgContour,imgResult]))\n",
    "cv2.imshow(\"Result\", imgStack)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Chapter 9\n",
    "\n",
    "\n",
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#faceCascade = cv2.CascadeClassifier(\"Resouces/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Resources/mfaces.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img,(600,400))\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 350), dtype=uint8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " imgGray[200:400:,0:350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Face\", imgGray)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the faces from grayscale\n",
    "faces = face_cascade.detectMultiScale(imgGray,1.4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the faces and \n",
    "count = 0\n",
    "counteyes = 0\n",
    "for (x,y,w,h) in faces:\n",
    "    count+=1\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = imgGray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        counteyes+=1\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "\n",
    "cv2.putText(img,\"Total faces:=\"+str(count)+\" eyes:= \"+str(counteyes),(img.shape[1]-250,img.shape[0]-50),cv2.FONT_HERSHEY_COMPLEX,0.4,(255,255,255),1)\n",
    "cv2.imshow('img',img)\n",
    "#cv2.imshow('roi_color',roi_color)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "## Draw paint using the webcam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "framewidth = 640\n",
    "frameheight = 480\n",
    "\n",
    "# width \n",
    "cap.set(3,framewidth)\n",
    "\n",
    "# height \n",
    "cap.set(4,frameheight)\n",
    "\n",
    "# brightness\n",
    "cap.set(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolour = {\"yellow\":[0,179,61,249,0,255]}\n",
    "\n",
    "# function to select colour \n",
    "def findColor(img,mycolour,col='yellow'):\n",
    "     # converting to hsv image\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # creating a mask\n",
    "    h_min,h_max,s_min,s_max,v_min,v_max = mycolour[col]\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    "\n",
    "    # stackking and giving the image \n",
    "    imgStack = stackImages(0.5,([img,imgHSV],[mask,imgResult]))\n",
    "    return(imgStack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = True\n",
    "while out:\n",
    "    success, img = cap.read()\n",
    "    imgStack = findColor(img,mycolour,'yellow')\n",
    "    \n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        out = False\n",
    "        cv2.waitKey(0)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 107, 0, 19, 255, 255]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycolour[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min,h_max,s_min,s_max,v_min,v_max = mycolour[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_max\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
